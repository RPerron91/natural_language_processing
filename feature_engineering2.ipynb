{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "symbolic link created for C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\data\\en <<===>> C:\\ProgramData\\Anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[+] Linking successful\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Converting words or sentences into numeric vectors is fundamental when working with text data. To make sure you are solid on how these vectors work, please generate the tf-idf vectors for the last three sentences of the example we gave at the beginning of this checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sentences = [\"The Lumberjack Song is the funniest Monty Python bit: I can't think of it without laughing.\",\n",
    "\"I would rather put strawberries on my ice cream for dessert, they have the best taste.\",\n",
    "\"The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "last_sentences_doc = nlp(' '.join(last_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sents = [[sent] for sent in last_sentences_doc.sents]\n",
    "\n",
    "sentences = pd.DataFrame(last_sents, columns=['text'])\n",
    "for i, sentence in enumerate(sentences['text']):\n",
    "    sentences.loc[i, 'text'] = ' '.join(\n",
    "        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accompaniment</th>\n",
       "      <th>bit</th>\n",
       "      <th>caramel</th>\n",
       "      <th>cream</th>\n",
       "      <th>dessert</th>\n",
       "      <th>fantastic</th>\n",
       "      <th>funniest</th>\n",
       "      <th>good</th>\n",
       "      <th>ice</th>\n",
       "      <th>laugh</th>\n",
       "      <th>lumberjack</th>\n",
       "      <th>mint</th>\n",
       "      <th>monty</th>\n",
       "      <th>python</th>\n",
       "      <th>song</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>taste</th>\n",
       "      <th>tasty</th>\n",
       "      <th>think</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349498</td>\n",
       "      <td>0.459548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459548</td>\n",
       "      <td>0.349498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459548</td>\n",
       "      <td>0.349498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.385323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385323</td>\n",
       "      <td>0.293048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293048</td>\n",
       "      <td>0.385323</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accompaniment       bit   caramel     cream   dessert  fantastic  funniest  \\\n",
       "0       0.000000  0.353553  0.000000  0.000000  0.000000   0.000000  0.353553   \n",
       "1       0.000000  0.000000  0.000000  0.349498  0.459548   0.000000  0.000000   \n",
       "2       0.385323  0.000000  0.385323  0.293048  0.000000   0.385323  0.000000   \n",
       "\n",
       "       good       ice     laugh  lumberjack      mint     monty    python  \\\n",
       "0  0.000000  0.000000  0.353553    0.353553  0.000000  0.353553  0.353553   \n",
       "1  0.459548  0.349498  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.293048  0.000000    0.000000  0.385323  0.000000  0.000000   \n",
       "\n",
       "       song  strawberry     taste     tasty     think  \n",
       "0  0.353553    0.000000  0.000000  0.000000  0.353553  \n",
       "1  0.000000    0.459548  0.349498  0.000000  0.000000  \n",
       "2  0.000000    0.000000  0.293048  0.385323  0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    use_idf=True, norm=u'l2', smooth_idf=True)\n",
    "\n",
    "# applying the vectorizer\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) In the 2-grams example, we only used 2-grams as our features. This time, use both 1-grams and 2-grams together as your feature set. Run the same models in the example and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# Get rid of chapter headers by using regular expressions\n",
    "persuasion = re.sub(r'Chapter \\d+','', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*','', alice)\n",
    "\n",
    "# Use text cleaning function defined above\n",
    "persuasion = text_cleaner(persuasion)\n",
    "alice = text_cleaner(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the cleaned novels\n",
    "nlp = spacy.load('en')\n",
    "persuasion_doc = nlp(persuasion)\n",
    "alice_doc = nlp(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Sir, Walter, Elliot, ,, of, Kellynch, Hall, ,...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(This, was, the, page, at, which, the, favouri...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\")</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Walter, Elliot, ,, born, March, ,, ,, married...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Anne, ,, born, August, ,, ;, a, still, -, bor...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author\n",
       "0  (Sir, Walter, Elliot, ,, of, Kellynch, Hall, ,...  Austen\n",
       "1  (This, was, the, page, at, which, the, favouri...  Austen\n",
       "2                                                (\")  Austen\n",
       "3  (Walter, Elliot, ,, born, March, ,, ,, married...  Austen\n",
       "4  (Anne, ,, born, August, ,, ;, a, still, -, bor...  Austen"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make lists of sentences and the author name\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "\n",
    "# put lists into dataframe\n",
    "sentences = pd.DataFrame(persuasion_sents + alice_sents, columns=['text', 'author'])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of stopwords/punctuation and lemmatize the tokens\n",
    "for i, sentence in enumerate(sentences['text']):\n",
    "    sentences.loc[i, 'text'] = ' '.join(\n",
    "        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able bear</th>\n",
       "      <th>able persuade</th>\n",
       "      <th>abominate</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absence home</th>\n",
       "      <th>absent</th>\n",
       "      <th>...</th>\n",
       "      <th>young people</th>\n",
       "      <th>young person</th>\n",
       "      <th>young sister</th>\n",
       "      <th>young woman</th>\n",
       "      <th>youth</th>\n",
       "      <th>youth say</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sir Walter Elliot Kellynch Hall Somersetshire ...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>page favourite volume open ELLIOT KELLYNCH HALL</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Walter Elliot bear March marry July Elizabeth ...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Anne bear August bear son November Mary bear N...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abide  ability  able  able bear  able persuade  abominate  abroad  absence  \\\n",
       "0    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "1    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "2    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "3    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "4    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "\n",
       "   absence home  absent  ...  young people  young person  young sister  \\\n",
       "0           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "1           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "2           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "3           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "4           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "\n",
       "   young woman  youth  youth say  zeal  zealous  \\\n",
       "0          0.0    0.0        0.0   0.0      0.0   \n",
       "1          0.0    0.0        0.0   0.0      0.0   \n",
       "2          0.0    0.0        0.0   0.0      0.0   \n",
       "3          0.0    0.0        0.0   0.0      0.0   \n",
       "4          0.0    0.0        0.0   0.0      0.0   \n",
       "\n",
       "                                                text  author  \n",
       "0  Sir Walter Elliot Kellynch Hall Somersetshire ...  Austen  \n",
       "1    page favourite volume open ELLIOT KELLYNCH HALL  Austen  \n",
       "2                                                     Austen  \n",
       "3  Walter Elliot bear March marry July Elizabeth ...  Austen  \n",
       "4  Anne bear August bear son November Mary bear N...  Austen  \n",
       "\n",
       "[5 rows x 5521 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=2, use_idf=True, norm=u'l2', smooth_idf=True, ngram_range=(1,2))\n",
    "\n",
    "# applying the vectorizer\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([tfidf_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
    "\n",
    "# keep in mind that the log base 2 of 1 is 0,\n",
    "# so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9028047764509859\n",
      "\n",
      "Test set score: 0.8642232403165347\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.973340738683699\n",
      "\n",
      "Test set score: 0.8779675135360266\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8611496806442654\n",
      "\n",
      "Test set score: 0.8429820907955019\n"
     ]
    }
   ],
   "source": [
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text','author'], 1))\n",
    "\n",
    "# We split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\n",
    "\n",
    "# Models\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
