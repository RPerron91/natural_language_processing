{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\LEGION\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "symbolic link created for C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\data\\en <<===>> C:\\ProgramData\\Anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[+] Linking successful\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from time import time\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import spacy\n",
    "import markovify\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'twitter_sentiment'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "data = pd.read_sql_query('SELECT * FROM twitter', con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      0  570306133677760513           neutral                        1.0000   \n",
       "1      1  570301130888122368          positive                        0.3486   \n",
       "2      2  570301083672813571           neutral                        0.6837   \n",
       "3      3  570301031407624196          negative                        1.0000   \n",
       "4      4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0           None                        NaN  Virgin America   \n",
       "1           None                     0.0000  Virgin America   \n",
       "2           None                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                   None     cairdin                None              0   \n",
       "1                   None    jnardino                None              0   \n",
       "2                   None  yvonnalynn                None              0   \n",
       "3                   None    jnardino                None              0   \n",
       "4                   None    jnardino                None              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.        None   \n",
       "1  @VirginAmerica plus you've added commercials t...        None   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...        None   \n",
       "3  @VirginAmerica it's really aggressive to blast...        None   \n",
       "4  @VirginAmerica and it's a really big bad thing...        None   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800           None  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800           None  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800           None  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800           None  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['index', 'tweet_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', ' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\",'',text)\n",
    "    text = re.sub(r'(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b', ' ',text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = text_cleaner(' '.join(data.text))\n",
    "positive_data = text_cleaner(' '.join(data[data['airline_sentiment'] == 'positive']['text']))\n",
    "negative_data = text_cleaner(' '.join(data[data['airline_sentiment'] == 'negative']['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "nlp.max_length = 20000000\n",
    "doc = nlp(text_data)\n",
    "positive_doc = nlp(positive_data)\n",
    "negative_doc = nlp(negative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = ' '.join([sent.text for sent in doc.sents if len(sent.text) > 1])\n",
    "positive_sents = ' '.join([sent.text for sent in positive_doc.sents if len(sent.text) > 1])\n",
    "negative_sents = ' '.join([sent.text for sent in negative_doc.sents if len(sent.text) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSifiedText(markovify.Text):\n",
    "    \n",
    "    def word_split(self, sentence):\n",
    "        return [\"::\".join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
    "\n",
    "    def word_join(self, words):\n",
    "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Markov chain model by using only the negative sentiment tweets. Generate some random sentences. Are the generated sentences exhibit the same negative sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_generator = POSifiedText(negative_sents, state_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your service SUCKS # usairwayssuck @USAirways I do n't get sarcasm , making computers more and more like real people .\n",
      "--------------\n",
      "@united As a Million Miler I 've been waiting @SouthwestAir can you follow me I will DM you my confirmation number when I get no benefits ? ! @VirginAmerica congrats , you just made it Tues , I ca n't watch my pre - paid DirectTV .\n",
      "--------------\n",
      "@USAirways do n't think you guys could not wait minutes .\n",
      "--------------\n",
      "Step  do n't suck so much @SouthwestAir I 'm upset because we were lied to .\n",
      "--------------\n",
      "@JetBlue @fllairport best way to do this online .\n",
      "--------------\n",
      "Ca n't find or anywhere @JetBlue Noooo ! ! Why is every single one getting delayed ?\n",
      "--------------\n",
      "Not usual gr8 southwest customer service I 've ever seen that .\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(negative_generator.make_sentence())\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the previous task this time bu using only the positive sentiment tweets. Generate some random sentences and observe whether they exhibit positive sentiment or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_generator = POSifiedText(positive_sents, state_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USAirways - Janet & amp ; an upgrade .\n",
      "--------------\n",
      "None\n",
      "--------------\n",
      "@AmericanAir will award me , air miles ! ! ! AA1679 Another successful journey , thanks for your excellent customer service 2day , BUT I have a complaint .\n",
      "--------------\n",
      "The new screens are laptop - large & amp ; carrying his daughter .\n",
      "--------------\n",
      "None\n",
      "--------------\n",
      "ðŸ˜‰ @JetBlue flight . proud to fly Jet Blue @JetBlue Start including PTO in your getaway packages and I 'm sure it 's just a rock ...\n",
      "--------------\n",
      "Thank you ! ! ! ! That 's super helpful .\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(positive_generator.make_sentence())\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This time train your Markov chain model using all the tweets and generate some random sentences. Can you say something systematic about the sentiments of the generated tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_generator = POSifiedText(sents, state_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SouthwestAir Anyone answering phone this morning at our plane was malfunctioning .\n",
      "--------------\n",
      "@AmericanAir I took the exact same plane again .\n",
      "--------------\n",
      "# eternity # 5amMisery @JetBlue should I bother contacting them ?\n",
      "--------------\n",
      "Thanks for a great flight @SouthwestAir is not being delayed because flight attendant did n't come to work !\n",
      "--------------\n",
      "@USAirways you are supposed to be in adjacent seats , not across isle .\n",
      "--------------\n",
      "@united worst flight experience I 've ever used thanks for nothing .\n",
      "--------------\n",
      "Where my free miles at ? ! @united of course this morning I see a non - stop flight between Laguardia / dal into a stop in STL .\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(all_tweets_generator.make_sentence())\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you isolate the sentiment of the text, the generated responses tended to match the tone of the text fairly well. When trained on text that is more generalized, the responses kind of make sense in context, but the tone of the text can go either way (one sentence starts using language that would be considered having a positive sentiment, but the generated ending's tone doesn't match that even though the sentence structure seems otherwise normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
